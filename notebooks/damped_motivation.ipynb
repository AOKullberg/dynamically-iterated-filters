{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f5600f20-a7f8-4390-ae34-237797be4d36",
   "metadata": {},
   "source": [
    "# Motivational example for damped DIF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e57f8070-23b7-4000-9687-3694ddb84c0a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "jax.config.update(\"jax_enable_x64\", True)\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.gridspec import GridSpec\n",
    "from matplotlib.widgets import Slider\n",
    "import ssmjax.algs as algs\n",
    "import ssmjax.transforms.linearization as linearization\n",
    "import ssmjax.types as types\n",
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6d8c934-b8da-4fce-a6f9-2a28eb7273e4",
   "metadata": {},
   "source": [
    "### Setup the problem and the algorithms\n",
    "\n",
    "Transition and measurement functions are changeable -- it does obviously change the end result. In the end of the notebook, there is an interactive tool that lets you play with the parameters of the model to find particular parameter values and initial points that cause divergence for the different filters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b394c4e4-8857-46b0-8475-7d3a15775dcf",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def transition(x, *args, **kwargs):\n",
    "    dx = jnp.cos(x)*jnp.sin(x)*x**2\n",
    "    return jnp.atleast_1d(jnp.vstack([dx]).squeeze())\n",
    "def measurement(x, *args, **kwargs):\n",
    "    y = jnp.arctan(x)\n",
    "    return jnp.atleast_1d(jnp.vstack([y]).squeeze())\n",
    "\n",
    "Q = jnp.array([[1.]])\n",
    "R = jnp.array([[1.]])\n",
    "x0 = jnp.array([1.])\n",
    "x = jnp.array([0.])\n",
    "P0 = jnp.array([[1.]])\n",
    "y = jnp.array([2.])\n",
    "x1 = np.linspace(-5, 5, 100)\n",
    "x2 = np.linspace(-5, 5, 100)\n",
    "def loss(x1, x2, y, Q, R, x0, P0, x):\n",
    "    # Compare the \"true\" transition -- xT is the true state\n",
    "    te = jnp.atleast_1d(x2 - transition(x1))\n",
    "    # Compare the \"true\" measurement -- x is the true state\n",
    "    me = jnp.atleast_1d(measurement(transition(x)) - measurement(x2))\n",
    "    # pe = jnp.atleast_1d(x1 - x0)\n",
    "    pe = jnp.atleast_1d(x1 - x0)\n",
    "    return (\n",
    "        te @ jnp.linalg.solve(Q, te[:, None])\n",
    "        + me @ jnp.linalg.solve(R, me[:, None])\n",
    "        + pe @ jnp.linalg.solve(P0, pe[:, None])\n",
    "    ).squeeze()\n",
    "\n",
    "mloss = jax.jit(jax.vmap(loss, (0, 0, None, None, None, None, None, None), 0))\n",
    "vloss = jax.jit(\n",
    "    jax.vmap(\n",
    "        jax.vmap(loss, (0, None, None, None, None, None, None, None), 0),\n",
    "        (None, 0, None, None, None, None, None, None),\n",
    "        0,\n",
    "    )\n",
    ")\n",
    "\n",
    "import jaxopt\n",
    "theta = types.MVNormal(jnp.zeros(1,), cov=None)\n",
    "propagate = jax.jit(jax.tree_util.Partial(algs.build_propagate(types.LinearizationMethod(linearization.first_taylor), transition), theta=theta))\n",
    "update = jax.jit(jax.tree_util.Partial(algs.build_update(types.LinearizationMethod(linearization.first_taylor), measurement), theta=theta))\n",
    "smooth = jax.jit(jax.tree_util.Partial(algs.build_smooth(types.LinearizationMethod(linearization.first_taylor), transition), theta=theta))\n",
    "\n",
    "def ls_loss(\n",
    "        prior,\n",
    "        observation,\n",
    "        observation_covariance,\n",
    "        transition_covariance,\n",
    "        updated_iterate,\n",
    "        smoothed_iterate,\n",
    "    ):\n",
    "        ye = observation - measurement(updated_iterate)\n",
    "        te = updated_iterate - transition(smoothed_iterate)\n",
    "        xp = prior.mean - smoothed_iterate\n",
    "        # Observation loss\n",
    "        Vy = ye.T @ jnp.linalg.solve(observation_covariance, ye)\n",
    "        # Transition loss\n",
    "        Vt = te.T @ jnp.linalg.solve(transition_covariance, te)\n",
    "        # Prior loss\n",
    "        Vp = xp.T @ jnp.linalg.solve(prior.cov, xp)\n",
    "        return Vy + Vt + Vp\n",
    "\n",
    "def find_stepsize(previous_state, observation, observation_covariance, transition_covariance, old_updated, old_smoothed, current_updated, current_smoothed, options):\n",
    "    def fun(x):\n",
    "            new_updated, new_smoothed = jnp.split(x, 2)\n",
    "            V = ls_loss(\n",
    "                previous_state,\n",
    "                observation,\n",
    "                observation_covariance,\n",
    "                transition_covariance,\n",
    "                new_updated.squeeze(),\n",
    "                new_smoothed.squeeze(),\n",
    "            )\n",
    "            return V\n",
    "    xk = jnp.vstack([old_updated.mean, old_smoothed.mean]).squeeze()\n",
    "    pi_upd = current_updated.mean - old_updated.mean\n",
    "    pi_smth = current_smoothed.mean - old_smoothed.mean\n",
    "    pi = jnp.vstack([pi_upd, pi_smth]).squeeze()\n",
    "\n",
    "    ls = jaxopt.BacktrackingLineSearch(\n",
    "        fun=fun,\n",
    "        maxiter=20,\n",
    "        condition=\"strong-wolfe\",\n",
    "        decrease_factor=options.linesearch.beta,\n",
    "        c1=options.linesearch.gamma,\n",
    "    )\n",
    "    stepsize, _ = ls.run(init_stepsize=1.0, params=xk, descent_direction=pi)\n",
    "    return stepsize\n",
    "\n",
    "def compute_ekf_solution(y, Q, R, x0, P0):\n",
    "    prior = types.MVNormal(x0, cov=P0)\n",
    "    predicted, _ = propagate(prior=prior, transition_covariance=Q, linearization_point=types.MVNormal(x0, cov=P0))\n",
    "    _, (updated, _) = update(predicted=predicted, observation=y, observation_covariance=R, linearization_point=predicted)\n",
    "    return prior, updated\n",
    "\n",
    "def iekf_inner_loop(carry, _):\n",
    "    predicted, y, R, updated = carry\n",
    "    _, (new_updated, _) = update(predicted=predicted, observation=y, observation_covariance=R, linearization_point=updated)\n",
    "    return (predicted, y, R, new_updated), new_updated\n",
    "\n",
    "def compute_iekf_solution(y, Q, R, x0, P0, iterations):\n",
    "    prior = types.MVNormal(x0, cov=P0)\n",
    "    predicted, _  = propagate(prior=prior, transition_covariance=Q, linearization_point=prior)\n",
    "    _, (updated, _) = update(predicted=predicted, observation=y, observation_covariance=R, linearization_point=predicted)\n",
    "    \n",
    "    _, seq_updated = jax.lax.scan(iekf_inner_loop, (predicted, y, R, updated), jnp.arange(iterations-1))\n",
    "    seq_updated = jax.tree_map(\n",
    "                lambda y, z: jnp.concatenate([y[None, ...], z], 0),\n",
    "                updated,\n",
    "                seq_updated,\n",
    "            )\n",
    "    seq_prior = jax.tree_map(lambda x: jnp.repeat(x[None, ...], seq_updated.mean.shape[0], 0), prior)\n",
    "    return seq_prior, seq_updated\n",
    "\n",
    "def diekf_inner_loop(carry, _):\n",
    "    prior, y, R, Q, updated, smoothed = carry\n",
    "    predicted, _ = propagate(prior=prior, transition_covariance=Q, linearization_point=smoothed)\n",
    "    _, (new_updated, _) = update(predicted=predicted, observation=y, observation_covariance=R, linearization_point=updated)\n",
    "    new_smoothed, _ = smooth(filtered_state=prior, smoothed_state=updated, transition_covariance=Q, linearization_point=smoothed)\n",
    "    return (prior, y, R, Q, new_updated, new_smoothed), (new_updated, new_smoothed)\n",
    "\n",
    "def compute_diekf_solution(y, Q, R, x0, P0, iterations):\n",
    "    prior = types.MVNormal(x0, cov=P0)\n",
    "    predicted, _  = propagate(prior=prior, transition_covariance=Q, linearization_point=prior)\n",
    "    _, (updated, _) = update(predicted=predicted, observation=y, observation_covariance=R, linearization_point=predicted)\n",
    "    smoothed, _ = smooth(filtered_state=prior, smoothed_state=updated, transition_covariance=Q, linearization_point=prior)\n",
    "    \n",
    "    _, (seq_updated, seq_smoothed) = jax.lax.scan(diekf_inner_loop,\n",
    "                                                  (prior, y, R, Q, updated, smoothed),\n",
    "                                                  jnp.arange(iterations-1))\n",
    "    seq_updated = jax.tree_map(\n",
    "                lambda y, z: jnp.concatenate([y[None, ...], z], 0),\n",
    "                updated,\n",
    "                seq_updated,\n",
    "            )\n",
    "    seq_smoothed = jax.tree_map(\n",
    "                lambda y, z: jnp.concatenate([y[None, ...], z], 0),\n",
    "                smoothed,\n",
    "                seq_smoothed,\n",
    "            )\n",
    "    return seq_smoothed, seq_updated\n",
    "\n",
    "def lsdiekf_inner_loop(carry, _):\n",
    "    prior, y, R, Q, options, updated, smoothed = carry\n",
    "    predicted, _ = propagate(prior=prior, transition_covariance=Q, linearization_point=smoothed)\n",
    "    _, (new_updated, _) = update(predicted=predicted, observation=y, observation_covariance=R, linearization_point=updated)\n",
    "    new_smoothed, _ = smooth(filtered_state=prior, smoothed_state=updated, transition_covariance=Q, linearization_point=smoothed)\n",
    "    stepsize = find_stepsize(prior, y, R, Q, updated, smoothed, new_updated, new_smoothed, options)\n",
    "    new_updated = types.MVNormal((1-stepsize)*updated.mean + stepsize*new_updated.mean, cov=new_updated.cov)\n",
    "    new_smoothed = types.MVNormal((1-stepsize)*smoothed.mean + stepsize*new_smoothed.mean, cov=new_smoothed.cov)\n",
    "    return (prior, y, R, Q, options, new_updated, new_smoothed), (new_updated, new_smoothed)\n",
    "\n",
    "def compute_lsdiekf_solution(y, Q, R, x0, P0, iterations, options=types.options.LineSearchIterationOptions()):\n",
    "    prior = types.MVNormal(x0, cov=P0)\n",
    "    predicted, _  = propagate(prior=prior, transition_covariance=Q, linearization_point=prior)\n",
    "    _, (updated, _) = update(predicted=predicted, observation=y, observation_covariance=R, linearization_point=predicted)\n",
    "    smoothed, _ = smooth(filtered_state=prior, smoothed_state=updated, transition_covariance=Q, linearization_point=prior)\n",
    "\n",
    "    _ , (seq_updated, seq_smoothed) = jax.lax.scan(lsdiekf_inner_loop, (prior, y, R, Q, options, updated, smoothed), jnp.arange(iterations-1))\n",
    "\n",
    "    seq_updated = jax.tree_map(\n",
    "                lambda y, z: jnp.concatenate([y[None, ...], z], 0),\n",
    "                updated,\n",
    "                seq_updated,\n",
    "            )\n",
    "    seq_smoothed = jax.tree_map(\n",
    "                lambda y, z: jnp.concatenate([y[None, ...], z], 0),\n",
    "                smoothed,\n",
    "                seq_smoothed,\n",
    "            )\n",
    "    return seq_smoothed, seq_updated"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7304f78-3a64-416c-a8f1-c1153df9f950",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Compute solutions for paper example\n",
    "This obviously only works **if** you haven't changed the transition and measurement function definitions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83253e49-82e6-436d-af74-6978c7c6aa3a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "q = jnp.array([[0.1]])\n",
    "r = jnp.array([[1.]])\n",
    "p = jnp.array([[1.]])\n",
    "xk = jnp.array([-3.2])\n",
    "y = measurement(transition(xk))\n",
    "x0n = jnp.array([-2.9])\n",
    "ekf_opt = compute_ekf_solution(y, q, r, x0n, p)\n",
    "iekf_opt = compute_iekf_solution(y, q, r, x0n, p, 10)\n",
    "diekf_opt = compute_diekf_solution(y, q, r, x0n, p, 10)\n",
    "lsdiekf_opt = compute_lsdiekf_solution(y, q, r, x0n, p, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4508b7d8-4796-48c2-bea6-5822be305811",
   "metadata": {},
   "source": [
    "### Produce paper example plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "577479e3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x1 = np.arange(-5., -2.01, 0.05)\n",
    "x2 = np.arange(-5., 5.01, 0.05)\n",
    "X1, X2 = jnp.meshgrid(x1, x2)\n",
    "V = vloss(x1, x2, y, q, r, x0n, p, xk)\n",
    "(row, col) = np.unravel_index(V.argmin(), V.shape)\n",
    "Vx0 = loss(x0n, transition(x0n), y, q, r, x0n, p, xk)\n",
    "plt.close(\"all\")\n",
    "fs = 16\n",
    "plt.rc('ytick', labelsize=fs)\n",
    "plt.rc('xtick', labelsize=fs)\n",
    "fig = plt.figure(figsize=(8, 8))#, layout=\"constrained\")\n",
    "gs = GridSpec(nrows=4, ncols=4, figure=fig, left=0.075, right=.99,\n",
    "            bottom=.075, top=.99,\n",
    "                      hspace=0.0, wspace=0.0)\n",
    "ax = []\n",
    "joint = fig.add_subplot(gs[:-1, 1:])\n",
    "marg2 = fig.add_subplot(gs[:-1, 0], sharey=joint)\n",
    "marg1 = fig.add_subplot(gs[-1, 1:], sharex=joint)\n",
    "\n",
    "joint.contourf(X1, X2, V, levels=15, cmap=\"Oranges\")\n",
    "joint.plot(X1[row, col], X2[row, col], '*', color='tab:orange', label='Optima', markersize=14)\n",
    "joint.hlines(X2[row, col], xmin=x1.min(), xmax=x1.max(), color='tab:orange', lw=.5)\n",
    "joint.vlines(X1[row, col], ymin=x2.min(), ymax=x2.max(), color='tab:orange', lw=.5)\n",
    "joint.plot(iekf_opt[0].mean, iekf_opt[1].mean, '--', marker='.', color='tab:blue', markersize=14, label='IEKF')\n",
    "joint.plot(diekf_opt[0].mean, diekf_opt[1].mean, '--', marker='.', color='tab:green', markersize=14, label='DIEKF')\n",
    "joint.plot(lsdiekf_opt[0].mean, lsdiekf_opt[1].mean, '--', marker='.', color='tab:red', markersize=14, label='LSDIEKF')\n",
    "joint.plot(x0n, transition(x0n), 'k', marker='*', lw=.5, label='Prior')\n",
    "joint.vlines(x0n, ymin=x2.min(), ymax=x2.max(), color='k', lw=.5)\n",
    "joint.hlines(transition(x0n), xmin=x1.min(), xmax=x1.max(), color='k', lw=.5)\n",
    "joint.set(ylim=[x2.min(), x2.max()], \n",
    "          xlim=[x1.min(), x1.max()],)\n",
    "joint.tick_params(labelbottom=False, bottom=False, left=False, labelleft=False)\n",
    "leg = joint.legend(fontsize=16, loc='lower left', bbox_to_anchor=(-.35, -.35))\n",
    "leg.set_in_layout(False)\n",
    "\n",
    "marg2.plot(V[:, col], X2[:, col], 'k')\n",
    "marg2.plot(V[row, col], X2[row, col], '*', color='tab:orange', markersize=14)\n",
    "marg2.set(xticklabels='', xticks=[], xlim=[V[:, col].min()-0.1*V[:,col].mean(), V[:, col].max()])\n",
    "marg2.set_ylabel(\"$X_1$\", fontsize=16)\n",
    "marg1.plot(X1[row, :], V[row, :], 'k')\n",
    "marg1.plot(X1[row, col], V[row, col], '*', color='tab:orange', markersize=14, label='Optima')\n",
    "marg1.set(yticklabels='', yticks=[], ylim=[V[row, :].min()-0.1*V[row, :].mean(), V[row, :].max()+0.1*V[row,:].mean()])\n",
    "marg1.set_xlabel(\"$X_0$\", fontsize=16)\n",
    "marg1.vlines(X1[row, col], ymin=marg1.get_ylim()[0], ymax=marg1.get_ylim()[1], color='tab:orange', lw=.5)\n",
    "marg2.hlines(X2[row, col], xmin=marg2.get_xlim()[0], xmax=marg2.get_xlim()[1], color='tab:orange', lw=.5)\n",
    "\n",
    "iekf_cost = mloss(iekf_opt[0].mean, iekf_opt[1].mean, y, q, r, x0n, p, xk)\n",
    "marg1.plot(iekf_opt[0].mean, iekf_cost, '--', marker='.', markersize=14, color='tab:blue', label='IEKF')\n",
    "marg2.plot(iekf_cost, iekf_opt[1].mean, '--', marker='.', markersize=14, color='tab:blue')\n",
    "diekf_cost = mloss(diekf_opt[0].mean, diekf_opt[1].mean, y, q, r, x0n, p, xk)\n",
    "marg1.plot(diekf_opt[0].mean, diekf_cost, '--', marker='.', markersize=14, color='tab:green', label='DIEKF')\n",
    "marg2.plot(diekf_cost, diekf_opt[1].mean, '--', marker='.', markersize=14, color='tab:green')\n",
    "lsdiekf_cost = mloss(lsdiekf_opt[0].mean, lsdiekf_opt[1].mean, y, q, r, x0n, p, xk)\n",
    "marg1.plot(lsdiekf_opt[0].mean, lsdiekf_cost, '--', marker='.', markersize=14, color='tab:red', label='LSDIEKF')\n",
    "marg2.plot(lsdiekf_cost, lsdiekf_opt[1].mean, '--', marker='.', markersize=14, color='tab:red')\n",
    "marg2.yaxis.set_label_coords(-.15, 0.5)\n",
    "marg1.vlines(x0n, ymin=marg1.get_ylim()[0], ymax=marg1.get_ylim()[1], color='k', lw=.5)\n",
    "marg2.hlines(transition(x0n), xmin=marg2.get_xlim()[0], xmax=marg2.get_xlim()[1], color='k', lw=.5)\n",
    "\n",
    "plt.savefig(\"damped_dif_motivation.eps\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74d2b722-6a0f-4374-bb10-ef9a30599346",
   "metadata": {},
   "source": [
    "### \"Divergence finder\"\n",
    "\n",
    "Interactive tool to find specific examples that diverge. Plots the loss and the IEKF/DIEKF solutions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45701208",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X1, X2 = jnp.meshgrid(x1, x2)\n",
    "V = vloss(x1, x2, y, Q, R, x0, P0, x)\n",
    "(row, col) = np.unravel_index(V.argmin(), V.shape)\n",
    "\n",
    "plt.close(\"all\")\n",
    "fig = plt.figure(figsize=(10, 8))\n",
    "gs = GridSpec(5, 6, figure=fig)\n",
    "\n",
    "ax = []\n",
    "joint = fig.add_subplot(gs[:-1, 1:-1])\n",
    "marg2 = fig.add_subplot(gs[:-1, 0])\n",
    "marg1 = fig.add_subplot(gs[-1, 1:-1])\n",
    "\n",
    "marg1_loss, = marg1.plot(X1[row, :], V[row, :])\n",
    "marg1_opt, = marg1.plot(X1[row, col], V[row, col], '*', color='tab:orange')\n",
    "marg2_loss, = marg2.plot(V[:, col], X2[:, col])\n",
    "marg2_opt, = marg2.plot(V[row, col], X2[row, col], '*', color='tab:orange')\n",
    "\n",
    "marg1.set(xlim=[x1.min(), x1.max()], yticklabels='', ylim=[V[row, :].min(), V[row, :].max()])\n",
    "marg2.set(ylim=[x2.min(), x2.max()], xticklabels='', xlim=[V[:, col].min(), V[:, col].max()])\n",
    "\n",
    "ekf_opt = compute_ekf_solution(measurement(transition(x)), Q, R, x0, P0)\n",
    "iekf_opt = compute_iekf_solution(measurement(transition(x)), Q, R, x0, P0, 3)\n",
    "diekf_opt = compute_diekf_solution(measurement(transition(x)), Q, R, x0, P0, 3)\n",
    "ekf_cost = mloss(ekf_opt[0].mean, ekf_opt[1].mean, y, Q, R, x0, P0, x)\n",
    "iekf_cost = mloss(iekf_opt[0].mean, iekf_opt[1].mean, y, Q, R, x0, P0, x)\n",
    "diekf_cost = mloss(diekf_opt[0].mean, diekf_opt[1].mean, y, Q, R, x0, P0, x)\n",
    "\n",
    "marg1_ekf, = marg1.plot(ekf_opt[0].mean, ekf_cost, '--', marker='^', color='tab:red')\n",
    "marg1_iekf, = marg1.plot(iekf_opt[0].mean, iekf_cost, '--', marker='^', color='tab:purple')\n",
    "marg1_diekf, = marg1.plot(diekf_opt[0].mean, diekf_cost, '--', marker='^', color='tab:green')\n",
    "marg2_ekf, = marg2.plot(ekf_cost, ekf_opt[1].mean, '--', marker='^', color='tab:red')\n",
    "marg2_iekf, = marg2.plot(iekf_cost, iekf_opt[1].mean, '--', marker='^', color='tab:purple')\n",
    "marg2_diekf, = marg2.plot(diekf_cost, diekf_opt[1].mean, '--', marker='^', color='tab:green')\n",
    "\n",
    "ekfsol, = joint.plot(ekf_opt[0].mean, ekf_opt[1].mean, '--', marker='^', color='tab:red', label='EKF')\n",
    "iekfsol, = joint.plot(iekf_opt[0].mean, iekf_opt[1].mean, '--', marker='^', color='tab:purple', label='IEKF')\n",
    "diekfsol, = joint.plot(diekf_opt[0].mean, diekf_opt[1].mean, '--', marker='^', color='tab:green', label='DIEKF')\n",
    "\n",
    "C = joint.contourf(X1, X2, V, levels=20)\n",
    "joint.set(xlabel=\"$x_1$\", ylabel=\"$x_2$\")\n",
    "optima, = joint.plot(X1[row, col], X2[row, col], '*', color='tab:orange', label='Optima')\n",
    "joint.vlines(x0, ymin=x2.min(), ymax=x2.max(), color='k', label='$x_0$')\n",
    "joint.hlines(X2[row, col], xmin=x1.min(), xmax=x1.max(), color='tab:orange', lw=.5)\n",
    "joint.vlines(X1[row, col], ymin=x2.min(), ymax=x2.max(), color='tab:orange', lw=.5)\n",
    "joint.hlines(transition(x), xmin=x1.min(), xmax=x1.max(), color='w', lw=.5)\n",
    "joint.vlines(x, ymin=x2.min(), ymax=x2.max(), color='w', lw=.5)\n",
    "xt, = joint.plot(x, transition(x), '*', color='w', label='True state')\n",
    "obs, = joint.plot(measurement(transition(x)), transition(x), 'y*', label='$y$')\n",
    "joint.plot(x1, transition(x1), color='w', label='Transition function')\n",
    "joint.plot(measurement(x2), x2, color='y', label='Measurement function')\n",
    "joint.set(title=\"Optimal point, $(x_1,x_2)=({:.2f},{:.2f})$\\nTrue point, $(x_1,x_2)=({:.2f},{:.2f})$\".format(X1[row, col], X2[row, col], x[0], transition(x)[0]), ylim=[x2.min(), x2.max()], xlim=[x1.min(), x1.max()])\n",
    "\n",
    "joint.legend(fontsize=8, loc='upper left', bbox_to_anchor=(1, 1))\n",
    "plt.suptitle(\"Loss contours\")\n",
    "joint.set(xticklabels='', yticklabels='')\n",
    "\n",
    "fig.subplots_adjust(bottom=0.25)\n",
    "\n",
    "x0obs = fig.add_axes([0.1, 0.1, 0.3, 0.03])\n",
    "x0_slider = Slider(\n",
    "    ax=x0obs,\n",
    "    label='$x_0$',\n",
    "    valmin=x1.min(),\n",
    "    valmax=x1.max(),\n",
    "    valinit=x0[0],\n",
    "    valstep=.1,\n",
    ")\n",
    "\n",
    "xobs = fig.add_axes([0.1, 0.05, 0.3, 0.03])\n",
    "x_slider = Slider(\n",
    "    ax=xobs,\n",
    "    label='$x$',\n",
    "    valmin=x1.min(),\n",
    "    valmax=x1.max(),\n",
    "    valinit=x[0],\n",
    "    valstep=.1,\n",
    ")\n",
    "\n",
    "Qobs = fig.add_axes([0.6, 0.15, 0.3, 0.03])\n",
    "Q_slider = Slider(\n",
    "    ax=Qobs,\n",
    "    label='$Q$',\n",
    "    valmin=-4,\n",
    "    valmax=4,\n",
    "    valinit=np.log(Q[0, 0]),\n",
    "    valstep=.5,\n",
    ")\n",
    "Q_slider.valtext.set_text(Q[0,0])\n",
    "\n",
    "Robs = fig.add_axes([0.6, 0.1, 0.3, 0.03])\n",
    "R_slider = Slider(\n",
    "    ax=Robs,\n",
    "    label='$R$',\n",
    "    valmin=-4,\n",
    "    valmax=4,\n",
    "    valinit=np.log(R[0, 0]),\n",
    "    valstep=.5,\n",
    ")\n",
    "R_slider.valtext.set_text(R[0,0])\n",
    "\n",
    "P0obs = fig.add_axes([0.6, 0.05, 0.3, 0.03])\n",
    "P0_slider = Slider(\n",
    "    ax=P0obs,\n",
    "    label='$P_0$',\n",
    "    valmin=-4,\n",
    "    valmax=4,\n",
    "    valinit=np.log(P0[0, 0]),\n",
    "    valstep=.5,\n",
    ")\n",
    "P0_slider.valtext.set_text(P0[0,0])\n",
    "\n",
    "def slider_update(val):\n",
    "    q = 10**Q_slider.val\n",
    "    Q_slider.valtext.set_text(q)\n",
    "    r = 10**R_slider.val\n",
    "    R_slider.valtext.set_text(r)\n",
    "    p = 10**P0_slider.val\n",
    "    P0_slider.valtext.set_text(p)\n",
    "    \n",
    "    xk = transition(x_slider.val)\n",
    "    y = measurement(xk)\n",
    "\n",
    "    V = vloss(x1, x2, y, np.atleast_2d(q), np.atleast_2d(r), x0_slider.val, np.atleast_2d(p), x_slider.val)\n",
    "    (row, col) = np.unravel_index(V.argmin(), V.shape)\n",
    "    \n",
    "    for coll in joint.collections:\n",
    "        coll.remove()\n",
    "    C = joint.contourf(X1, X2, V, levels=20)\n",
    "    optima.set_data((X1[row, col],), (X2[row, col],))\n",
    "    obs.set_data((y,), (xk,))\n",
    "    xt.set_data((x_slider.val,), (xk,))\n",
    "    joint.vlines(x0_slider.val, ymin=x2.min(), ymax=x2.max(), color='k', label='$x_0$')\n",
    "    joint.hlines(X2[row, col], xmin=x1.min(), xmax=x1.max(), color='tab:orange', lw=.5)\n",
    "    joint.vlines(X1[row, col], ymin=x2.min(), ymax=x2.max(), color='tab:orange', lw=.5)\n",
    "    joint.hlines(xk, xmin=x1.min(), xmax=x1.max(), color='w', lw=.5)\n",
    "    joint.vlines(x_slider.val, ymin=x2.min(), ymax=x2.max(), color='w', lw=.5)\n",
    "\n",
    "    marg1_loss.set_data((X1[row, :],), (V[row, :],))\n",
    "    marg1_opt.set_data((X1[row, col],), (V[row, col],))\n",
    "    marg2_loss.set_data((V[:, col],), (X2[:, col],))\n",
    "    marg2_opt.set_data((V[row, col],), (X2[row, col],))\n",
    "    marg1.set(ylim=[V[row, :].min(), V[row, :].max()])\n",
    "    marg2.set(xlim=[V[:, col].min(), V[:, col].max()])\n",
    "\n",
    "    esol = compute_ekf_solution(np.atleast_1d(y), np.atleast_2d(q), np.atleast_2d(r), np.atleast_1d(x0_slider.val), np.atleast_2d(p))\n",
    "    ekf_cost = mloss(esol[0].mean, esol[1].mean, y, Q, R, x0, P0, x)\n",
    "    marg1_ekf.set_data((esol[0].mean,), (ekf_cost,))\n",
    "    marg2_ekf.set_data((ekf_cost,), (esol[1].mean,))\n",
    "    ekfsol.set_data((esol[0].mean,), (esol[1].mean,))\n",
    "    ###\n",
    "    iesol = compute_iekf_solution(np.atleast_1d(y), np.atleast_2d(q), np.atleast_2d(r), np.atleast_1d(x0_slider.val), np.atleast_2d(p), 5)\n",
    "    iekf_cost = mloss(iesol[0].mean, iesol[1].mean, y, Q, R, x0, P0, x)\n",
    "    marg1_iekf.set_data((iesol[0].mean,), (iekf_cost,))\n",
    "    marg2_iekf.set_data((iekf_cost,), (iesol[1].mean,))\n",
    "    iekfsol.set_data((iesol[0].mean,), (iesol[1].mean,))\n",
    "    ###\n",
    "    diesol = compute_diekf_solution(np.atleast_1d(y), np.atleast_2d(q), np.atleast_2d(r), np.atleast_1d(x0_slider.val), np.atleast_2d(p), 5)\n",
    "    diekf_cost = mloss(diesol[0].mean, diesol[1].mean, y, Q, R, x0, P0, x)\n",
    "    diekfsol.set_data((diesol[0].mean,), (diesol[1].mean,))\n",
    "    marg1_diekf.set_data((diesol[0].mean,), (diekf_cost,))\n",
    "    marg2_diekf.set_data((diekf_cost,), (diesol[1].mean,))\n",
    "\n",
    "    joint.set_title(\"Optimal point, $(x_1,x_2)=({:.2f},{:.2f})$\\nTrue point, $(x_1,x_2)=({:.2f},{:.2f})$\".format(X1[row, col], X2[row, col], x_slider.val, transition(x_slider.val)[0]))\n",
    "    plt.draw()\n",
    "\n",
    "x0_slider.on_changed(slider_update)\n",
    "x_slider.on_changed(slider_update)\n",
    "Q_slider.on_changed(slider_update)\n",
    "R_slider.on_changed(slider_update)\n",
    "P0_slider.on_changed(slider_update)\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
